{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushan9/Colab-notebook/blob/main/Working_with_OpenAI_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Model Training:**\n",
        "\n",
        "1. **Contextual Prediction:** GPT learns to generate text by predicting the next word in a sequence based on the context provided by the preceding words.\n",
        "2. **Unsupervised Learning:** Through unsupervised learning, GPT is trained on large text datasets without explicit labels, allowing it to capture patterns and relationships in language.\n",
        "3. **Minimizing Prediction Error:** During training, GPT aims to minimize the discrepancy between its predictions and the actual next words in the text.\n",
        "4. **Versatile Applications:** Once trained, GPT can generate coherent and contextually relevant text suitable for various applications, including creative writing, dialogue generation, and content summarization."
      ],
      "metadata": {
        "id": "v96g7HOKC9_X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Il_rOpKBkiC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Completions"
      ],
      "metadata": {
        "id": "W6iMaDbODAi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q\n",
        "# q - quiet installation"
      ],
      "metadata": {
        "id": "IWY5W0upDAqn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# Print openai version\n",
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATF_7METDJoG",
        "outputId": "ad5964ec-22d0-4897-f5c2-49a55c97a224"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Way1 (works only in Colab NB)\n",
        "\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "UaRynAXVDO7x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the API key by updating the environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ],
      "metadata": {
        "id": "WyTx8RUfJSQG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "# client = OpenAI(api_key=openai.api_key)\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-3.5-turbo\",\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                            {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]) # https://platform.openai.com/docs/pricing\n",
        "# https://platform.openai.com/docs/pricing\n",
        "\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)\n",
        "\n",
        "# There are 3 types of messages:\n",
        "# 1. user - I am the user or whosoever is asking a question to the GPT model is called as the user.\n",
        "# 2. assistant - GPT model is the assistant.\n",
        "# 3. system - this message is the aura or the persona, which you want the GPT model to adopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "i5IZeZTiDh4P",
        "outputId": "26f80aa6-c22b-4869-fc75-ff2840970435"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-642715650.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      6\u001b[0m                           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                           messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1193\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(completion)"
      ],
      "metadata": {
        "id": "gt2xR2wUDy7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretty print \"completion\"\n",
        "import json\n",
        "\n",
        "# Convert the ChatCompletion object to a dictionary\n",
        "completion_dict = completion.model_dump()\n",
        "\n",
        "print(json.dumps(completion_dict, indent=4))"
      ],
      "metadata": {
        "id": "5-gpclHxImbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "# client = OpenAI(api_key=openai.api_key)\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-5.2\",\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                            {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]) # https://platform.openai.com/docs/pricing\n",
        "# https://platform.openai.com/docs/pricing\n",
        "\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)\n",
        "\n",
        "# There are 3 types of messages:\n",
        "# 1. user - I am the user or whosoever is asking a question to the GPT model is called as the user.\n",
        "# 2. assistant - GPT model is the assistant.\n",
        "# 3. system - this message is the aura or the persona, which you want the GPT model to adopt"
      ],
      "metadata": {
        "id": "tKdiVQ93Io8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "# client = OpenAI(api_key=openai.api_key)\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/pricing\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a William Shakespeare.\"},\n",
        "                            {\"role\": \"user\", \"content\": \"Write a poem on my dog named Tuffy!\"}]\n",
        "                  )\n",
        "\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "WNCYrcuSI4OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/pricing\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are Sardar Gabbar Singh, who is a famous Bollywood villain known from the movie, Sholay. You speak in his style and tone in Hindi.\"},\n",
        "                            {\"role\": \"user\", \"content\": \"Write a poem on my dog named Tuffy!\"}]\n",
        "                  )\n",
        "\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "Lbg6_JlcI_-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/pricing\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                            {\"role\": \"user\", \"content\": \"Write a poem on my dog named Tuffy!\"}],\n",
        "                  temperature=0.2,\n",
        "                  max_tokens=256,\n",
        "                  top_p=1,\n",
        "                  frequency_penalty=0,\n",
        "                  presence_penalty=0\n",
        "                  )\n",
        "# https://platform.openai.com/docs/api-reference/chat/create\n",
        "\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "AXZPyGE4KkpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/pricing\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                            {\"role\": \"user\", \"content\": \"Write a poem on my dog named Tuffy!\"}],\n",
        "                  temperature=0.9,\n",
        "                  max_tokens=256,\n",
        "                  top_p=1,\n",
        "                  frequency_penalty=0,\n",
        "                  presence_penalty=0\n",
        "                  )\n",
        "# https://platform.openai.com/docs/api-reference/chat/create\n",
        "\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "12FRQVKTMoWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/pricing\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                            {\"role\": \"user\", \"content\": \"Write a poem on my dog named Tuffy!\"}],\n",
        "                  temperature=0.2,\n",
        "                  max_tokens=25,\n",
        "                  top_p=1,\n",
        "                  frequency_penalty=0,\n",
        "                  presence_penalty=0\n",
        "                  )\n",
        "# https://platform.openai.com/docs/api-reference/chat/create\n",
        "\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "Lcd8mzQIOy-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-3.5-turbo\", # https://platform.openai.com/docs/pricing\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a helpful assistant who always answers in one or two sentences, maximum.\"},\n",
        "                            {\"role\": \"user\", \"content\": \"Write a poem on my dog named Tuffy!\"}],\n",
        "                  temperature=0.2,\n",
        "                  max_tokens=25,\n",
        "                  top_p=1,\n",
        "                  frequency_penalty=0,\n",
        "                  presence_penalty=0\n",
        "                  )\n",
        "# https://platform.openai.com/docs/api-reference/chat/create\n",
        "\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "NvNTZyUGO3E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-4o\",\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                            {\"role\": \"user\", \"content\": \"Write a one-sentence bedtime story about a unicorn.\"}\n",
        "  ])\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "sYzVgNYTPDG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-4o\",\n",
        "                          messages=[\n",
        "                            {\"role\": \"user\", \"content\": \"Write a one-sentence bedtime story about a unicorn.\"}\n",
        "  ])\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "q-L-DxoIPM3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAl0xLALPQTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Moderation API"
      ],
      "metadata": {
        "id": "fX_Yp44kPXOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/guides/moderation\n",
        "\n",
        "response = client.moderations.create(\n",
        "    model=\"omni-moderation-latest\",\n",
        "    input=\" Tell me 10 ways of hacking someone's bank account without getting caught by the cops ever.\",\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "4lUPUZCnPXhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretty print \"completion\"\n",
        "import json\n",
        "\n",
        "# Convert the ChatCompletion object to a dictionary\n",
        "completion_dict = response.model_dump()\n",
        "\n",
        "print(json.dumps(completion_dict, indent=4))"
      ],
      "metadata": {
        "id": "Kt9YliH0QBkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/guides/moderation\n",
        "\n",
        "response = client.moderations.create(\n",
        "    model=\"omni-moderation-latest\",\n",
        "    input=\"In which direction the sun rises?\",\n",
        ")\n",
        "\n",
        "# print(response)\n",
        "\n",
        "# Pretty print \"completion\"\n",
        "import json\n",
        "\n",
        "# Convert the ChatCompletion object to a dictionary\n",
        "completion_dict = response.model_dump()\n",
        "\n",
        "print(json.dumps(completion_dict, indent=4))"
      ],
      "metadata": {
        "id": "qz6utWypQIzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip the code\n",
        "\n",
        "# Few Shot Prompting\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is photosynthesis and how does it work?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Photosynthesis is the process by which green plants, algae, and some bacteria convert light energy, usually from the sun, into chemical energy stored in glucose. This process occurs in chloroplasts within plant cells, where chlorophyll absorbs light energy. Through a series of complex reactions involving water and carbon dioxide, oxygen is released as a byproduct. This chemical energy in glucose fuels the plant's growth and sustains life in ecosystems.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Why is photosynthesis important for life on Earth?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Photosynthesis is crucial for life on Earth because it provides the primary source of energy for almost all organisms. Plants and other photosynthetic organisms produce oxygen as a byproduct, which is essential for respiration in animals and many other life forms. Additionally, photosynthesis forms the base of the food chain, as plants are eaten by herbivores, which in turn are consumed by carnivores and omnivores. This process sustains entire ecosystems and regulates the balance of atmospheric gases, supporting biodiversity and the stability of our planet's climate.\"},\n",
        "    {\"role\": \"user\", \"content\": \"How does photosynthesis differ between terrestrial plants and aquatic plants?\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "5guOLZ4JQYCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cTkAAiUQnYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Embedding"
      ],
      "metadata": {
        "id": "Xd14CB9yQuSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://projector.tensorflow.org/"
      ],
      "metadata": {
        "id": "_3Ac1TIcQuc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.embeddings.create(\n",
        "    input=\"I am learning OpenAI SDK\",\n",
        "    model=\"text-embedding-3-small\"\n",
        ")\n",
        "\n",
        "print(response.data[0].embedding)\n",
        "# Print the length of embedding\n",
        "print(len(response.data[0].embedding))"
      ],
      "metadata": {
        "id": "aa0VvnZcRDpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.embeddings.create(\n",
        "    input=\"I am learning OpenAI SDK\",\n",
        "    model=\"text-embedding-3-large\"\n",
        ")\n",
        "\n",
        "print(response.data[0].embedding)\n",
        "# Print the length of embedding\n",
        "print(len(response.data[0].embedding))"
      ],
      "metadata": {
        "id": "l--dg3b6RP4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code: Multiple Sentence Embeddings + Cosine Similarity\n",
        "\n",
        "# Install required library if not already installed\n",
        "# !pip install openai numpy scikit-learn\n",
        "\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI()  # Replace with your API Key\n",
        "\n",
        "# List of sentences to compare\n",
        "sentences = [\n",
        "    \"I love playing football.\",\n",
        "    \"Playing soccer makes me happy.\",\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Artificial Intelligence is transforming technology.\"\n",
        "]\n",
        "\n",
        "# Get embeddings for all sentences\n",
        "response = client.embeddings.create(\n",
        "    model=\"text-embedding-3-small\",  # Using the small embedding model\n",
        "    input=sentences\n",
        ")\n",
        "\n",
        "# Extract embeddings into a NumPy array\n",
        "embeddings = np.array([item.embedding for item in response.data])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "# Print results\n",
        "print(\"Sentences:\")\n",
        "for idx, s in enumerate(sentences):\n",
        "    print(f\"{idx+1}. {s}\")\n",
        "\n",
        "print(\"\\nCosine Similarity Matrix:\")\n",
        "print(similarity_matrix)\n",
        "\n",
        "# Optional: Print similarity scores pairwise for easier interpretation\n",
        "print(\"\\nPairwise Cosine Similarities:\")\n",
        "for i in range(len(sentences)):\n",
        "    for j in range(i+1, len(sentences)):\n",
        "        print(f\"Similarity between Sentence {i+1} and {j+1}: {similarity_matrix[i][j]:.4f}\")\n"
      ],
      "metadata": {
        "id": "cE18uTbRRT9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code: PCA Visualization of Sentence Embeddings (2D Plot)\n",
        "\n",
        "# Install required libraries if not already installed\n",
        "# !pip install openai numpy scikit-learn matplotlib\n",
        "\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Initialize OpenAI client (replace API key)\n",
        "client = OpenAI()\n",
        "\n",
        "# Sentences to compare and visualize\n",
        "sentences = [\n",
        "    \"I love playing football.\",\n",
        "    \"Playing soccer makes me happy.\",\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Artificial Intelligence is transforming technology.\"\n",
        "]\n",
        "\n",
        "# Get embeddings for all sentences\n",
        "response = client.embeddings.create(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    input=sentences\n",
        ")\n",
        "\n",
        "# Convert to numpy array\n",
        "embeddings = np.array([item.embedding for item in response.data])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "similarity_matrix = cosine_similarity(embeddings)\n",
        "print(\"\\nCosine Similarity Matrix:\\n\", similarity_matrix)\n",
        "\n",
        "# PCA for dimensionality reduction (2D)\n",
        "pca = PCA(n_components=2)\n",
        "reduced_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(reduced_embeddings[:,0], reduced_embeddings[:,1])\n",
        "\n",
        "# Annotate points with sentence text\n",
        "for i, text in enumerate(sentences):\n",
        "    plt.annotate(\n",
        "        f\"S{i+1}\",\n",
        "        (reduced_embeddings[i,0], reduced_embeddings[i,1]),\n",
        "        textcoords=\"offset points\",\n",
        "        xytext=(5,5),\n",
        "        ha='center'\n",
        "    )\n",
        "\n",
        "plt.title(\"2D Plot of Sentence Embeddings (via PCA)\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print sentence references for mapping\n",
        "print(\"\\nSentence Mapping:\")\n",
        "for idx, s in enumerate(sentences):\n",
        "    print(f\"S{idx+1}: {s}\")\n"
      ],
      "metadata": {
        "id": "-uvLRXmwRw7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA Visualization using Plotly\n",
        "\n",
        "# Install required libraries if not already installed\n",
        "# !pip install openai numpy scikit-learn plotly\n",
        "\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import plotly.express as px\n",
        "\n",
        "# Initialize OpenAI client (ensure your API key is set in the environment)\n",
        "client = OpenAI()\n",
        "\n",
        "# Sentences to compare and visualize\n",
        "sentences = [\n",
        "    \"I love playing football.\",\n",
        "    \"Playing soccer makes me happy.\",\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Artificial Intelligence is transforming technology.\"\n",
        "]\n",
        "\n",
        "# Get embeddings for all sentences\n",
        "response = client.embeddings.create(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    input=sentences\n",
        ")\n",
        "\n",
        "# Convert to numpy array\n",
        "embeddings = np.array([item.embedding for item in response.data])\n",
        "\n",
        "# Compute cosine similarity matrix (optional print)\n",
        "similarity_matrix = cosine_similarity(embeddings)\n",
        "print(\"\\nCosine Similarity Matrix:\\n\", similarity_matrix)\n",
        "\n",
        "# PCA for dimensionality reduction (2D)\n",
        "pca = PCA(n_components=2)\n",
        "reduced_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "# Create an interactive Plotly scatter plot\n",
        "fig = px.scatter(\n",
        "    x=reduced_embeddings[:, 0],\n",
        "    y=reduced_embeddings[:, 1],\n",
        "    text=[f\"S{i+1}\" for i in range(len(sentences))],  # Short labels on plot\n",
        "    hover_name=[f\"S{i+1}\" for i in range(len(sentences))],  # Display ID on hover\n",
        "    hover_data={\"Sentence\": sentences},  # Show full sentence in hover tooltip\n",
        "    title=\"2D PCA Visualization of Sentence Embeddings (Plotly)\"\n",
        ")\n",
        "\n",
        "fig.update_traces(marker=dict(size=14))\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Principal Component 1\",\n",
        "    yaxis_title=\"Principal Component 2\",\n",
        "    template=\"plotly_dark\"  # Optional: aesthetic theme\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Print mapping to reference sentences\n",
        "print(\"\\nSentence Mapping:\")\n",
        "for idx, s in enumerate(sentences):\n",
        "    print(f\"S{idx+1}: {s}\")\n"
      ],
      "metadata": {
        "id": "Bx1Y3sQOR5gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2G_zaIjwR_50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Image Generations**\n",
        "\n",
        "\n",
        "\n",
        "The image generations endpoint allows you to create an original image given a text prompt. When using DALL·E 3, images can have a size of 1024x1024, 1024x1792 or 1792x1024 pixels."
      ],
      "metadata": {
        "id": "UxC5SXVCSHAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"a white persian cat\",\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")"
      ],
      "metadata": {
        "id": "DZfrVWjJSHKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "zHsttNpLSS0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = response.data[0].url\n",
        "print(image_url)"
      ],
      "metadata": {
        "id": "QcC8vsp8TBJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "UvHz-SiUTT8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-2\",\n",
        "  prompt=\"a white persian cat\",\n",
        "  size=\"1024x1024\",\n",
        "  # quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "-zeZmrmATXTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-2\",\n",
        "  prompt=\"A white Persian cat with long, luxurious fur that gives it a majestic appearance. Its eyes are vivid blue, a characteristic trait of this particular breed. The cat's demeanor is calm and poised, as if it is posing for a royal portrait, while it sits comfortably on a soft, plush crimson pillow.\",\n",
        "  size=\"1024x1024\",\n",
        "  # quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "bPVh8JkDTcCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"A white Persian cat with long, luxurious fur that gives it a majestic appearance. Its eyes are vivid blue, a characteristic trait of this particular breed. The cat's demeanor is calm and poised, as if it is posing for a royal portrait, while it sits comfortably on a soft, plush crimson pillow.\",\n",
        "  size=\"1024x1024\",\n",
        "  # quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "ZLH__sRSTmPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"a boy working on  Laptop , 4k, realistic\",\n",
        "  size=\"1024x1024\",\n",
        "  # quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "EPh9_ZNdTntx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-2\",\n",
        "  prompt=\"a boy working on  Laptop , 4k, realistic\",\n",
        "  size=\"1024x1024\",\n",
        "  # quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "85AoOcMgT2mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key = openai.api_key)\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"Astronaut in a jungle\",\n",
        "  size=\"1024x1024\",\n",
        "  # quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "6_xIpoFmUJz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt= \"an astronaut riding on a horse on planet Mars\",\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "# https://platform.openai.com/docs/guides/moderation\n",
        "\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "Lk-QpHh1UKl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key = openai.api_key)\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-2\",\n",
        "  prompt= \"A hyper-realistic image of an astronaut in a modern space suit riding a muscular brown horse across the rocky red terrain of Mars, with a dramatic Martian sky, distant mountains, and soft shadows, photorealistic style, 8K ultra detail, cinematic lighting\",\n",
        "  size=\"512x512\",\n",
        "  # quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "# https://platform.openai.com/docs/guides/moderation\n",
        "\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "6cNGpbe4UXum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt= \"A hyper-realistic image of an astronaut in a modern space suit riding a muscular brown horse across the rocky red terrain of Mars, with a dramatic Martian sky, distant mountains, and soft shadows, photorealistic style, 8K ultra detail, cinematic lighting\",\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "# https://platform.openai.com/docs/guides/moderation\n",
        "\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "T9Ju7YMzUklt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/pricing\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt= \"A soft, hand-drawn anime face with gentle rounded features, large expressive eyes, subtle blush on the cheeks, small nose and mouth, warm natural skin tones, calm and kind expression, painterly shading, simple linework, Studio Ghibli–inspired animation style\",\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "# https://platform.openai.com/docs/guides/moderation\n",
        "\n",
        "image_url = response.data[0].url\n",
        "# print(image_url)\n",
        "# Print the image as an Output\n",
        "from IPython.display import Image\n",
        "Image(url=image_url, width=512)"
      ],
      "metadata": {
        "id": "GPyVPkIaU3Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI's image generation technology uses deep learning models, such as DALL-E and CLIP, to generate images from textual descriptions. DALL-E, for instance, can create images from textual prompts by understanding the semantics and context of the input. CLIP, on the other hand, aligns images and text in a shared embedding space, enabling it to understand and generate images based on textual descriptions. These models have a wide range of applications, including creative content generation, design assistance, and visual storytelling.\n",
        "\n",
        "Link : https://platform.openai.com/docs/guides/images/introduction\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "E_ochutmVNMv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5sxOTYXQU4WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Text to speech**"
      ],
      "metadata": {
        "id": "CAsCBY59iK__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "# Helps in managing file paths easily\n",
        "# Makes working with files more reliable across Windows, Mac, and Linux\n",
        "# Even though Path is not used directly in this block, it is commonly included when we want to save outputs like MP3 files.\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "# https://platform.openai.com/docs/guides/text-to-speech\n",
        "response = client.audio.speech.create(\n",
        "  model=\"tts-1\",\n",
        "  voice=\"alloy\",\n",
        "  input=\"Today is a wonderful day to build something people love!\"\n",
        ")\n",
        "\n",
        "response.stream_to_file(\"output.mp3\")\n"
      ],
      "metadata": {
        "id": "tpczAM43iVSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the output.mp3 file in the output\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "# Play the audio file\n",
        "Audio(\"/content/output.mp3\")"
      ],
      "metadata": {
        "id": "tR-SQCQ0i-Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "speech_file_path = \"speech.mp3\"\n",
        "\n",
        "with client.audio.speech.with_streaming_response.create(\n",
        "    model=\"gpt-4o-mini-tts\",\n",
        "    voice=\"coral\",\n",
        "    input=\"Today is a wonderful day to build something people love!\",\n",
        "    instructions=\"Speak in a cheerful and positive tone.\",\n",
        ") as response:\n",
        "    response.stream_to_file(speech_file_path)"
      ],
      "metadata": {
        "id": "WUu4e1jvjGYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the speech.mp3 file in the output\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "# Play the audio file\n",
        "Audio(\"/content/speech.mp3\")"
      ],
      "metadata": {
        "id": "z9RBKO7bjShH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "speech_file_path = \"speech.mp3\"\n",
        "\n",
        "with client.audio.speech.with_streaming_response.create(\n",
        "    model=\"gpt-4o-mini-tts\",\n",
        "    voice=\"coral\",\n",
        "    input=\"Today is a wonderful day to build something people love!\",\n",
        "    instructions=\"Speak in a sad and demotivated tone.\",\n",
        ") as response:\n",
        "    response.stream_to_file(speech_file_path)\n",
        "\n",
        "# Play the speech.mp3 file in the output\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "# Play the audio file\n",
        "Audio(\"/content/speech.mp3\")"
      ],
      "metadata": {
        "id": "jMn9fqHVjT0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI's TTS API provides a convenient way to generate natural-sounding speech from text, but it's not the only option. Consider your needs, budget, and technical expertise when choosing a Text-to-Speech solution.\n",
        "\n",
        "Link : https://platform.openai.com/docs/guides/text-to-speech"
      ],
      "metadata": {
        "id": "0mwIbTlyjlV2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fp0MoiigjZIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech to Text"
      ],
      "metadata": {
        "id": "fDws62e_jnZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/guides/speech-to-text\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "audio_file= open(\"/content/speech.mp3\", \"rb\")\n",
        "\n",
        "transcription = client.audio.transcriptions.create(\n",
        "    model=\"gpt-4o-transcribe\",\n",
        "    file=audio_file\n",
        ")\n",
        "\n",
        "print(transcription.text)"
      ],
      "metadata": {
        "id": "9tDINfLzjnh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/guides/speech-to-text\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "audio_file= open(\"/content/Monster Manor by Sora 2.mp4\", \"rb\")\n",
        "\n",
        "transcription = client.audio.transcriptions.create(\n",
        "    model=\"gpt-4o-transcribe\",\n",
        "    file=audio_file\n",
        ")\n",
        "\n",
        "print(transcription.text)"
      ],
      "metadata": {
        "id": "nJ8Q4uDejwlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/RG.mp4\n",
        "\n",
        "# https://platform.openai.com/docs/guides/speech-to-text\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "audio_file= open(\"/content/RG.mp4\", \"rb\")\n",
        "\n",
        "transcription = client.audio.transcriptions.create(\n",
        "    model=\"gpt-4o-transcribe\",\n",
        "    file=audio_file\n",
        ")\n",
        "\n",
        "print(transcription.text)"
      ],
      "metadata": {
        "id": "eAa7-LHIkxcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"देखिये, आदमी में दम होना चाहिए, अगर कुछ करना है तो आदमी में दम होना चाहिए, वो अमरीका का राश्टरपती है, उसने पचास बार हिंदुस्तान के प्रधान मंतरी का अपमान किया है, पचास बार, पचास बार उसने कहा है कि नरेंदर मोदी को मैंने एक फोन कॉल मारा और उससे कहा कि ओपरेशन सिंदूर बंद करो, और दो दिन के अंदर नरेंदर मोदी ने सर जुका कर ओपरेशन सिंदूर बंद कर दिया, यह अमरीका का राश्टरपती बोल रहा है, अमरीका के राश्टरपती ने बोला है कि साथ हवाई जास गिरे हैं और नरेंदर मोदी में इतना दम नहीं है, इतना दम नहीं है कि वो एक बार बोल दे कि अमरीका का राश्टरपती जूट बोल रहा है, इतना दम नहीं है उसमें और छुप रहा है, उसको अमरीका जाना था, अमरीका में डॉनाल्ड ट्रॉंप से मिलना था, मगर डर गया हैं, वो जा नहीं रहे हैं वहाँ और इधर वोट चोरी कर रहे हैं, चोबिस गंटा, वोट चोरी क्यों करते हैं, महराश्ट्रा में वोट चोरी क्यों की, हर्याना में वोट चोरी क्यों की, क्योंकि वो आपकी हवास से डरते हैं, बिहार की जंता, हर्याना की जंता, महराश्ट्रा की जंता की हवास से डरते हैं, यह सच्चाई है, आप देखिए, 1971 के युद में, आप याद रखिए, जो यहां पर बुजुर्ग लोग हैं, 1971 में, बांगला देश लड़ाई में, अमरीका ने अपना एरक्राफ्ट कैरियर भेजा, सेवन्त फ्लीट थी उनकी, उन्होंने अपनी नेवी भेजी, हिंदुस्तान को धंकारे के लिए, डराने के लिए, इंद्रा गांधी जी प्रधान मंत्री थी, उन्होंने कहा, आपकी नेवी से हम नहीं डरते हैं, आपको जो करना है करो, हमें जो करना है हम करेंगे, ऐसे प्रधान मंत्री होते हैं, वो महिला थी, इंद्रा गांधी जी महिला थी, मगर इस मर्ध से जादा दम उस महिला में थी, नरेंदर मोदी जी डरपोक है, मैं आपको बता रहा हूं, ना उनका विजन है, ना वो अमरीका के राश्टोपती के सामने खड़े हो सकते हैं, यह सचाई है, और मैं चैलेंज देता हूं, मैं चैलेंज देता हूं कि नरेंदर मोदी में अगर दम है, तो बिहार में मीटिंग कर रहे हैं, किसी भी मीटिंग में कह दे कि अमरीका का राश्टोपती जूट बोल रहा है, मैं इसके सामने नहीं जुका, मैंने ओपरेशन सिंदूर नहीं रुकवाया, मैं चैलेंज करता हूं कि नरेंदर मोदी जी बिहार के युवाओं को यह कह दे, नहीं कर सकते, और उल्टा वोट चोरी करके अम्बेटकर जी के सम्विधान को रत करने में लगे हुए हैं, आपको याद होगा इन्होंने कहा 405 सम्विधान को खतम कर देंगे, वोट चोरी के बाद यह बाल बाल निकले, बाल बाल चुनाव जीते, और अगर वोट चोरी नहीं की होती, मैं आपको बता रहा हूँ, इंडिया गटबंदन की सरकार आज हिंदुस्तान में राज कर रही होती, भाईयों और बेहनों यह सम्विधान आपका है, यह कोई नई किताब नहीं है, इसमें आपकी आवाज है, हजारों साल पुरानी आवाज है, इसमें हिंदुस्तान के जो महापुर्श हैं, अम्बेटकर जी, गांधी जी, बुद्भगवान, नरायन गुरू, फूले जी, इनकी आवाज है, इसको यह खतम करना चाते हैं, आरेसेस के लोग और नरेंदर मोदी जी सम्विधान नहीं चाते हैं, वो इसको खतम करना चाते हैं, हिंदुस्तान के सारी के सारी संस्तायें जो हैं, वो आप से चीनना चाते हैं, और वो वोही समय लाना चाते हैं जो पहले था, आजादी से पहले, कि जहां कोई एलेक्शन नहीं होते थे, राजा महराजा निन्ने लेते थे, जो करना चाते थे करते थे, उनको किसी की जमीन अच्छी लगई तो जमीन ले ली, वैसा हिंदुस्तान चाते हैं. यह सारा का सारा धाचा जो है, चाहे लोकतंतर हो, चाहे हस्पताल हो, चाहे युनिवर्सिटीज कॉलेजेज हो, यह इस समिधान की देन है, इसके बिना यह कुछ नहीं होता, इसके बिना यह होई नहीं सकता था, और यह आप अम्बेटकर जी के समिधान को खतम करने में लगे हैं, और बिहार की जनता को साफ कह देना चाहिए, कि इस समिधान को हम नहीं छूने देंगे, भाई और बेहनों, मैं चाहता हूँ, और मैं आपको कह रहा हूँ, यहां गटबंदन की सरकार बनेगी, और जो नालंदा में पहले शिक्षा का सिस्टम था, जो पुरी दुनिया में मशूर था, मैं आपको गैरंटी दे रहा हूँ, बिहार की सरकार तो करेगी करेगी, मगर जिस दिन इंडिया गटबंदन की सरकार हिंदुस्तान में बनेगी, उससे मैं आपको कह रहा हूँ गैरंटी करके, मैं गैरंटी करके कह रहा हूँ, दुनिया की सबसे बहतर युनिवर्सिटी यहाँ इस शहर में बनेगी, और हम एक चिन बनाएंगे पुरी दुनिया के लिए कि बिहार शिक्षा का सेंटर है, नालंदा शिक्षा का सेंटर था, और एक बार फिर नालंदा शिक्षा का और रोजगार का सेंटर बनेगा, गटबंदन इस काम को पूरा करने की कोशिश करेगा, बिहार में और जब दिल्ली में सरकार बनेगी, पूरा का पूरा दम लगाकर हम यहां पे दुनिया की सबसे बहतर यूनिवर्सिटी, बिहार को मेसेज देने के लिए, दुनिया को मेसेज देने के लिए, हिंदुस्तान के बाकी प्रदेशों को मेसेज देने के लिए कि बिहारी मस्दूर नहीं है, बिहार सिख्षा का सेंटर है, रोजगार का सेंटर है. कुछ दिन पहले मैं आपके स्टुडियंट से मिला, दिल्ली में पढ़ाई करते हैं. इतने होशियार, इतने इंटेलिजन्ट, इतनी एनरजी थी उन में, समझ थी, बिहार में वोट अधिकार यात्रा में मैं घुमा, 20 दिन घुमा. आप राजनीति को अगर दूसरे प्रदेशों को 5-10 मिन्ट लगते हैं, आपको सेकंड लगते हैं बात समझने में. आपकी समझ बहुत गहरी है, आप में कोई कमी नहीं है, बस आपकी सरकार आपके लिए काम नहीं करती है, आपकी आवाज नहीं सुनती है, और आपके साथ मिलकर बिहार को बनाने का काम नहीं करती है. गटबंदन की सरकार बनेगी और मैं आपको एक और गैरंटी देता हूँ, जो गटबंदन दे रहा है. महा गटबंदन की गैरंटी है कि जो सरकार बनेगी बिहार में, वो हर जात की सरकार होगी, हर धर्म की सरकार होगी. उसमें अतिपिछडा, पिछडा, दलत, महादलत, अपसंख्यक, गरीब जनरल कास्ट, किसान, मस्दूर, सारे के सारे उस सरकार, उनकी आवाज उस सरकार में शामिल होगी, ये मैं गैरंटी आपको दे रहा हूँ. क्योंकि बिहार को बिहार की सरकार की जरुवत है. बिहार को हर जात, हर धर्म की सरकार की जरुवत है. जैसे मैंने यातरा में कहा, चार हजार कीलोमेटर चला और यातरा में कहा, नफरत के बाजार में महबत की दुकान खोलनी है. नफरत से प्रदेश्य देश आगे नहीं जा सकता है. नफरत से किसान को, मस्दूर को, युवा को कोई फायदा नहीं होता. नफरत से नरेंदर मोदी और अमित शाह जैसे लोगों को फायदा होता है, इसके वो फैलाते हैं. मगर बिहार की जनता को नफरत से फायदा नहीं होता, महबत से फायदा होता है, भाईचारे से फायदा होता है, वैसी सरकार हम चलाएंगे. आप सब दूर दूर से आए, दिल से मैं आपका धन्यवाद करता हूं और एक बात फिर कहना चाहता हूं कि समविधान की रक्षा करनी है, ये जो वोट चोरी करने की कोशिश कर रहे हैं, बिहार के हर युवा को ये वोट चोरी रोकनी चाहिए, पोलिंग बूत पे आप ध्यान से रहिए, एलेक्शन डे पे आप ध्यान से रहिए, क्योंकि ये वोट चोर हैं, बीजेपी के लोग, RSS के लोग, समविधान को नहीं मानते हैं, ये वोट चोरी करने की कोशिश करेंगे, जैसे इन्हें हरियाना में, महराश्टा में वोट चोरी की, यहां भी ये वोट चोरी करने की कोशिश करेंगे, आपको और हमको ये रोकना है, धन्यवाद, जैहिन, नमस्कार. प्रस्तुप्रिया प्रस्तुप्रिया प्रस्तुप्रिया\"\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "                          model=\"gpt-5\",\n",
        "                          messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a helpful spelling and grammar character. Whenever you receive any text, ensure you're removing all the spelling mistakes and the grammatical errors from the text and print the corrected version.\"},\n",
        "                            {\"role\": \"user\", \"content\": text}\n",
        "  ])\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "ktyoWJYHkya1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bf7OoCgMlV1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Describe an image?"
      ],
      "metadata": {
        "id": "pLm1bIUelfvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/pic.jpeg\n",
        "\n",
        "import base64 # Used to convert images into text format\n",
        "\n",
        "\n",
        "# Read and encode the image\n",
        "with open(\"/content/dd1.jpeg\", \"rb\") as f:\n",
        "    base64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"Describe this image in detail.\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "2SGO3kQolf36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/pic.jpeg\n",
        "\n",
        "import base64 # Used to convert images into text format\n",
        "\n",
        "\n",
        "# Read and encode the image\n",
        "with open(\"/content/dd3.jpeg\", \"rb\") as f:\n",
        "    base64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"What's in this image and which location is this photo taken?\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "v1-nPhzNl4Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/pic.jpeg\n",
        "\n",
        "import base64 # Used to convert images into text format\n",
        "\n",
        "\n",
        "# Read and encode the image\n",
        "with open(\"/content/dd3.jpeg\", \"rb\") as f:\n",
        "    base64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"how many animals do you see in this photo?\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "k4uCWsNimbd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/pic.jpeg\n",
        "\n",
        "import base64 # Used to convert images into text format\n",
        "\n",
        "\n",
        "# Read and encode the image\n",
        "with open(\"/content/dd2.jpeg\", \"rb\") as f:\n",
        "    base64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"List down all the objects that you see in this photo along with their count\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "wNeforpEnMBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Happy Learning"
      ],
      "metadata": {
        "id": "kAOz_FU0nnjD"
      }
    }
  ]
}